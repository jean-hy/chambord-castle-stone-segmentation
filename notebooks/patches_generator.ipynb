{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the patches from the refined folder into 256x256 patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1) Environment Setup\n",
    "# -------------------------------------------------------------\n",
    "# If your 'segment-anything' folder is in \"../third_party/segment-anything/\", append it:\n",
    "sys.path.append(\"../third_party/segment-anything/\")\n",
    "\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2) Load or Initialize Annotations from JSON\n",
    "# -------------------------------------------------------------\n",
    "annotations_path = \"../data/annotations/boxe.json\"\n",
    "if os.path.exists(annotations_path):\n",
    "    with open(annotations_path, \"r\") as f:\n",
    "        boxes_dict = json.load(f)\n",
    "else:\n",
    "    boxes_dict = {}  # Start with an empty dictionary if no file exists\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2.1) Define path to create_boxes.py\n",
    "# -------------------------------------------------------------\n",
    "create_boxes_script = \"../scripts/create_boxes.py\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3) Define build_totalmask() function\n",
    "# -------------------------------------------------------------\n",
    "def build_totalmask(pred) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Builds a binary mask from SAM predictions.\n",
    "    Stones = white (255), mortar = black (0).\n",
    "    Fills small holes using morphological closing.\n",
    "    \"\"\"\n",
    "    if len(pred) == 0:\n",
    "        return None\n",
    "\n",
    "    height, width = pred[0]['segmentation'].shape\n",
    "    total_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for seg in pred:\n",
    "        seg_bin = seg['segmentation'].astype(np.uint8)\n",
    "        total_mask += seg_bin\n",
    "\n",
    "    # Convert summed mask to binary with Otsu threshold\n",
    "    _, total_mask_bin = cv2.threshold(total_mask, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    # Fill small holes with morphological closing\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    total_mask_bin = cv2.morphologyEx(total_mask_bin, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return total_mask_bin\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4) Load the SAM Model and Create Generators/Predictors\n",
    "# -------------------------------------------------------------\n",
    "sam_checkpoint = \"../models/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "device = \"cpu\"  # Change to \"cuda\" if you have a GPU\n",
    "\n",
    "print(\"Loading SAM model on device:\", device)\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=32,       \n",
    "    pred_iou_thresh=0.86,     \n",
    "    stability_score_thresh=0.92,\n",
    "    crop_n_layers=1,\n",
    "    crop_n_points_downscale_factor=2,\n",
    "    min_mask_region_area=100\n",
    ")\n",
    "\n",
    "mask_predictor = SamPredictor(sam)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5) Process Images in the Refined Folder and Extract Patches\n",
    "# -------------------------------------------------------------\n",
    "refined_folder = \"../data/refined/img-stones\"\n",
    "output_dir_img = \"../data/patches/images\"\n",
    "output_dir_mask = \"../data/patches/masks\"\n",
    "os.makedirs(output_dir_img, exist_ok=True)\n",
    "os.makedirs(output_dir_mask, exist_ok=True)\n",
    "\n",
    "patch_size = 256   # 256x256 patches\n",
    "stride = 32        # 32 pixel stride (not too low because we want different patches)\n",
    "stone_threshold = 0.1  # At least 10% of patch must be stone\n",
    "\n",
    "image_files = [\n",
    "    f for f in os.listdir(refined_folder)\n",
    "    if f.lower().endswith((\".jpg\", \".JPG\",\".jpeg\", \".png\"))\n",
    "]\n",
    "\n",
    "patch_count = 0\n",
    "\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(refined_folder, img_file)\n",
    "    image_bgr = cv2.imread(img_path)\n",
    "    if image_bgr is None:\n",
    "        print(f\"Skipping {img_file} -> Unable to load image.\")\n",
    "        continue\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = image_rgb.shape\n",
    "    print(f\"\\n--- Processing {img_file} ---\")\n",
    "    print(f\"Image path: {img_path}\")\n",
    "    print(f\"Image size: {width} x {height}\")\n",
    "\n",
    "    # 5A) Generate Automatic Masks with SAM\n",
    "    masks_auto = mask_generator.generate(image_rgb)\n",
    "    print(f\"  Number of auto masks: {len(masks_auto)}\")\n",
    "    if len(masks_auto) == 0:\n",
    "        print(\"  No auto masks found; skipping.\")\n",
    "        continue\n",
    "\n",
    "    auto_mask_bin = build_totalmask(masks_auto)\n",
    "    if auto_mask_bin is None:\n",
    "        print(\"  auto_mask_bin is None; skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 5B) Display the image and its auto mask for inspection\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(auto_mask_bin, cmap=\"gray\")\n",
    "    plt.title(\"Automatic Mask (Stones=White, BG=Black)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # 5C) Check if annotation for missing stones exists\n",
    "    if img_file not in boxes_dict:\n",
    "        user_response = input(f\"Annotation for {img_file} not found. Annotate missing stones? (y/n): \")\n",
    "        if user_response.lower().startswith(\"y\"):\n",
    "            subprocess.run([\"python\", create_boxes_script, img_path])\n",
    "            if os.path.exists(\"temp_boxes.json\"):\n",
    "                with open(\"temp_boxes.json\", \"r\") as f:\n",
    "                    manual_boxes = json.load(f)\n",
    "                # Update the boxes_dict for the current image\n",
    "                boxes_dict[img_file] = manual_boxes\n",
    "                # Save the updated boxes_dict to the annotations file\n",
    "                with open(annotations_path, \"w\") as f:\n",
    "                    json.dump(boxes_dict, f, indent=2)\n",
    "                # Remove the temporary file\n",
    "                os.remove(\"temp_boxes.json\")\n",
    "            else:\n",
    "                print(\"Annotation file not updated; proceeding without manual boxes.\")\n",
    "\n",
    "    # 5D) Merge bounding box masks if they exist\n",
    "    if img_file in boxes_dict:\n",
    "        manual_boxes = boxes_dict[img_file]\n",
    "        if len(manual_boxes) > 0:\n",
    "            mask_predictor.set_image(image_rgb)\n",
    "            input_boxes = torch.tensor(manual_boxes, device=mask_predictor.device)\n",
    "            transformed_boxes = mask_predictor.transform.apply_boxes_torch(\n",
    "                input_boxes, image_rgb.shape[:2]\n",
    "            )\n",
    "            masks_box, scores, logits = mask_predictor.predict_torch(\n",
    "                point_coords=None,\n",
    "                point_labels=None,\n",
    "                boxes=transformed_boxes,\n",
    "                multimask_output=False\n",
    "            )\n",
    "            masks_box = masks_box.squeeze(1).cpu().numpy()\n",
    "            combined_mask_bool = auto_mask_bin.astype(bool)\n",
    "            for i in range(masks_box.shape[0]):\n",
    "                stone_bool = masks_box[i].astype(bool)\n",
    "                combined_mask_bool = np.logical_or(combined_mask_bool, stone_bool)\n",
    "            final_mask_bin = (combined_mask_bool.astype(np.uint8) * 255)\n",
    "        else:\n",
    "            final_mask_bin = auto_mask_bin\n",
    "    else:\n",
    "        final_mask_bin = auto_mask_bin\n",
    "\n",
    "    # 5E) Verify that the final mask contains stone areas\n",
    "    nz_count = cv2.countNonZero(final_mask_bin)\n",
    "    print(f\"  Non-zero pixels in final mask: {nz_count}\")\n",
    "    if nz_count == 0:\n",
    "        print(\"  Final mask is all black; skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 5F) Extract 256x256 patches from the final mask and original image\n",
    "    if height < patch_size or width < patch_size:\n",
    "        print(f\"  {img_file} is too small for {patch_size}x{patch_size} patches; skipping.\")\n",
    "        continue\n",
    "\n",
    "    # We will store the patches in lists for display\n",
    "    patch_imgs_list = []\n",
    "    patch_masks_list = []\n",
    "\n",
    "    for y in range(0, height - patch_size + 1, stride):\n",
    "        for x in range(0, width - patch_size + 1, stride):\n",
    "            patch_mask = final_mask_bin[y:y+patch_size, x:x+patch_size]\n",
    "            patch_img = image_rgb[y:y+patch_size, x:x+patch_size]\n",
    "\n",
    "            # Count how many stone pixels are in this patch\n",
    "            stone_pixels = cv2.countNonZero(patch_mask)\n",
    "            total_pixels = patch_size * patch_size\n",
    "\n",
    "            if stone_pixels > stone_threshold * total_pixels:\n",
    "                # Save patch to disk (convert image back to BGR)\n",
    "                patch_img_bgr = cv2.cvtColor(patch_img, cv2.COLOR_RGB2BGR)\n",
    "                patch_img_name = f\"patch_img_{patch_count}.png\"\n",
    "                patch_mask_name = f\"patch_mask_{patch_count}.png\"\n",
    "\n",
    "                cv2.imwrite(os.path.join(output_dir_img, patch_img_name), patch_img_bgr)\n",
    "                cv2.imwrite(os.path.join(output_dir_mask, patch_mask_name), patch_mask)\n",
    "\n",
    "                # Store for visualization\n",
    "                patch_imgs_list.append(patch_img)\n",
    "                patch_masks_list.append(patch_mask)\n",
    "\n",
    "                patch_count += 1\n",
    "\n",
    "    print(f\"  -> Patches saved from {img_file}: {len(patch_imgs_list)}\")\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # Display the valid patches in a 2-row layout:\n",
    "    #  - Top row: original patches\n",
    "    #  - Bottom row: mask patches (inverted so stones=black, BG=white)\n",
    "    # -------------------------------------------------------------\n",
    "    if len(patch_imgs_list) > 0:\n",
    "        fig, axes = plt.subplots(\n",
    "            2, len(patch_imgs_list), \n",
    "            figsize=(4*len(patch_imgs_list), 6)\n",
    "        )\n",
    "\n",
    "        for i in range(len(patch_imgs_list)):\n",
    "            # Top row: original patch\n",
    "            axes[0, i].imshow(patch_imgs_list[i])\n",
    "            axes[0, i].axis('off')\n",
    "\n",
    "            # Bottom row: invert the mask so stones=0(black), BG=255(white)\n",
    "            inverted_mask = cv2.bitwise_not(patch_masks_list[i])\n",
    "            axes[1, i].imshow(inverted_mask, cmap='gray')\n",
    "            axes[1, i].axis('off')\n",
    "\n",
    "        plt.suptitle(f\"Patches for {img_file}\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\nDone!\")\n",
    "print(\"Total patches saved:\", patch_count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
