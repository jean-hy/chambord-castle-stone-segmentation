{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import supervision as sv\n",
    "import importlib\n",
    "import torch\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries = [\"numpy\", \"torch\", \"matplotlib\", \"cv2\", \"math\", \"supervision\"]\n",
    "for lib in libraries:\n",
    "    try:\n",
    "        importlib.import_module(lib)\n",
    "        print(f\"{lib} ✅ Installed\")\n",
    "    except ImportError:\n",
    "        print(f\"{lib} ❌ NOT Installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../data/refined/img-stones/FSE_35_004.jpg'\n",
    "\n",
    "image_bgr = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)  # Convert BGR -> RGB\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Original Stone Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../third_party/segment-anything/\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"../models/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=32,\n",
    "    pred_iou_thresh=0.86,\n",
    "    stability_score_thresh=0.92,\n",
    "    crop_n_layers=1,\n",
    "    crop_n_points_downscale_factor=2,\n",
    "    # min_mask_region_area=10, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = mask_generator.generate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of masks generated:\", len(masks))\n",
    "print(\"Keys of the first mask:\", masks[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "show_anns(masks)\n",
    "plt.axis('off')\n",
    "plt.title(\"Color-Coded Segmentation (Automatic)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_totalmask(pred):\n",
    "    \"\"\"\n",
    "    Builds a binary mask (stone=white, mortar=black) from SAM predictions.\n",
    "    Optionally fill small holes with morphological close.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    height, width = pred[0]['segmentation'].shape\n",
    "    total_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Summation or logical OR approach\n",
    "    for seg in pred:\n",
    "        seg_bin = seg['segmentation'].astype(np.uint8)\n",
    "        total_mask += seg_bin  # Summation approach\n",
    "\n",
    "    # Otsu threshold to unify overlapping areas\n",
    "    _, total_mask_bin = cv2.threshold(total_mask, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    # Morphological close to fill small holes\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    total_mask_bin = cv2.morphologyEx(total_mask_bin, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(total_mask_bin, cmap='gray')\n",
    "    plt.title(\"Binary Mask of Stones (Automatic)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return total_mask_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mask_bin = build_totalmask(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show side-by-side\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(final_mask_bin, cmap='gray')\n",
    "plt.title(\"Binary Mask of Stones (Auto)\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Bounding Box Prompts for Missing Stones\n",
    "# We copy the bounding boxes from the \"create-boxes.py\" script output.\n",
    "# Paste that list into boxes_raw below.\n",
    "\n",
    "from segment_anything import SamPredictor\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 1) Initialize SamPredictor\n",
    "mask_predictor = SamPredictor(sam)\n",
    "mask_predictor.set_image(image)  # 'image' is your RGB image from earlier steps\n",
    "\n",
    "# 2) Define bounding boxes from your local script output\n",
    "#    Replace these tuples with the actual ones from create-boxes.py\n",
    "boxes_raw = [\n",
    "    (3, 14, 172, 93), (175, 13, 378, 88), (92, 110, 300, 200), (225, 307, 408, 390), (411, 304, 496, 391), (501, 304, 557, 384)\n",
    "]\n",
    "\n",
    "# Convert each tuple to a NumPy array\n",
    "boxes = [np.array(b) for b in boxes_raw]\n",
    "print(\"Boxes from local script:\", boxes)\n",
    "\n",
    "# Convert to Torch tensor on the correct device\n",
    "input_boxes = torch.tensor(boxes, device=mask_predictor.device)\n",
    "\n",
    "# 3) Transform boxes for SAM\n",
    "transformed_boxes = mask_predictor.transform.apply_boxes_torch(\n",
    "    input_boxes, \n",
    "    image.shape[:2]  # (height, width)\n",
    ")\n",
    "\n",
    "# 4) Predict masks for each bounding box\n",
    "masks_box, scores, logits = mask_predictor.predict_torch(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    boxes=transformed_boxes,\n",
    "    multimask_output=False\n",
    ")\n",
    "\n",
    "# masks_box shape: [num_boxes, 1, H, W]\n",
    "# Convert it to NumPy for further processing or merging with your automatic mask\n",
    "masks_box = masks_box.squeeze(1).cpu().numpy()  # -> shape: (num_boxes, H, W)\n",
    "\n",
    "print(\"Bounding box-based masks shape:\", masks_box.shape)\n",
    "print(\"Scores:\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize each bounding box mask\n",
    "for i in range(masks_box.shape[0]):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(masks_box[i], cmap='gray')\n",
    "    plt.title(f\"Box Mask {i}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Merge the Bounding Box Masks with the Automatic Mask\n",
    "\n",
    "# We'll do a logical OR so that any stone found by the bounding boxes is added to the final mask.\n",
    "\n",
    "final_mask_bool = final_mask_bin.astype(bool)  # convert auto mask to bool\n",
    "\n",
    "for i in range(masks_box.shape[0]):\n",
    "    stone_bool = masks_box[i].astype(bool)\n",
    "    final_mask_bool = np.logical_or(final_mask_bool, stone_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_mask_bin = final_mask_bool.astype(np.uint8) * 255\n",
    "# combined_mask_bin = cv2.bitwise_not(combined_mask_bin) # Invert if needed to get white stones on black background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the combined result\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(combined_mask_bin, cmap='gray')\n",
    "plt.title(\"Final Mask (Auto + Box Prompts)\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "print(\"Done! This final mask includes automatic segmentation plus bounding box corrections.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
